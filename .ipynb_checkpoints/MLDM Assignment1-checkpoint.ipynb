{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "10ac1fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f0431b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9c793034",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mu1: [6.4406 5.8386 6.7494 7.3581 7.7655 4.3671]\n",
      "mu2: [6.1988 5.8464 6.6064 6.1153 6.9309 4.3697]\n",
      "Sigma1 shape: (6, 6)\n",
      "Sigma2 shape: (6, 6)\n"
     ]
    }
   ],
   "source": [
    "# Loading data\n",
    "sigma1 = pd.read_csv('Sigma1.csv', header=None).values      # shape (6,6)\n",
    "sigma2 = pd.read_csv('Sigma2.csv', header=None).values      # shape (6,6)\n",
    "mu1 = pd.read_csv('M1.csv', header=None).values.flatten()   # shape (6,)\n",
    "mu2 = pd.read_csv('M2.csv', header=None).values.flatten()   # shape (6,)\n",
    "print(\"mu1:\", mu1)\n",
    "print(\"mu2:\", mu2)\n",
    "print(\"Sigma1 shape:\", sigma1.shape)\n",
    "print(\"Sigma2 shape:\", sigma2.shape)\n",
    "n = 10000\n",
    "p1 = 0.35\n",
    "p2 = 0.65"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5316089d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2a:\n",
    "# Genarting training set\n",
    "n1 = int(n * p1)\n",
    "n2 = n - n1\n",
    "X1_train = np.random.multivariate_normal(mean=mu1, cov=sigma1, size=n1)\n",
    "X2_train = np.random.multivariate_normal(mean=mu2, cov=sigma2, size=n2)\n",
    "y_train_1 = np.zeros(n1, dtype=int)\n",
    "y_train_2 = np.ones(n2, dtype=int)\n",
    "X_train = np.vstack([X1_train, X2_train])\n",
    "y_train = np.concatenate([y_train_1, y_train_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9de9b3b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 1: ||mu1 - mu1_hat|| = 0.0354, ||Sigma1 - Sigma1_hat||_F = 0.7196\n",
      "Class 2: ||mu2 - mu2_hat|| = 0.0517, ||Sigma2 - Sigma2_hat||_F = 0.3239\n"
     ]
    }
   ],
   "source": [
    "# 2b:\n",
    "# Computing the MLE estimators for each of the class\n",
    "def mle_mean_cov(X):\n",
    "    \"\"\"\n",
    "    X: matrix of shape (N, d)\n",
    "    returns: (mu_hat, sigma_hat)\n",
    "    \"\"\"\n",
    "    mu_hat = X.mean(axis=0)\n",
    "    sigma_hat = np.cov(X, rowvar=False, bias=True)\n",
    "    return mu_hat, sigma_hat\n",
    "X_train_class1 = X_train[y_train == 0]\n",
    "X_train_class2 = X_train[y_train == 1]\n",
    "mu1_hat, sigma1_hat = mle_mean_cov(X_train_class1)\n",
    "mu2_hat, sigma2_hat = mle_mean_cov(X_train_class2)\n",
    "def diff_norm(true_mu, est_mu, true_sigma, est_sigma):\n",
    "    mu_diff = np.linalg.norm(true_mu - est_mu)\n",
    "    sigma_diff = np.linalg.norm(true_sigma - est_sigma, ord='fro')\n",
    "    return mu_diff, sigma_diff\n",
    "\n",
    "mu1_diff, sigma1_diff = diff_norm(mu1, mu1_hat, sigma1, sigma1_hat)\n",
    "mu2_diff, sigma2_diff = diff_norm(mu2, mu2_hat, sigma2, sigma2_hat)\n",
    "\n",
    "print(f\"Class 1: ||mu1 - mu1_hat|| = {mu1_diff:.4f}, ||Sigma1 - Sigma1_hat||_F = {sigma1_diff:.4f}\")\n",
    "print(f\"Class 2: ||mu2 - mu2_hat|| = {mu2_diff:.4f}, ||Sigma2 - Sigma2_hat||_F = {sigma2_diff:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "90774a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2c:\n",
    "# Genarting validation set:\n",
    "n_val = 2000\n",
    "n_val_1 = int(n_val * p1)\n",
    "n_val_2 = n_val - n_val_1\n",
    "\n",
    "X_val_1 = np.random.multivariate_normal(mean=mu1, cov=sigma1, size=n_val_1)\n",
    "X_val_2 = np.random.multivariate_normal(mean=mu2, cov=sigma2, size=n_val_2)\n",
    "\n",
    "y_val_1 = np.zeros(n_val_1, dtype=int)\n",
    "y_val_2 = np.ones(n_val_2, dtype=int)\n",
    "\n",
    "X_val = np.vstack([X_val_1, X_val_2])\n",
    "y_val = np.concatenate([y_val_1, y_val_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "79c85a2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF params: n_estimators=50, max_depth=None, max_features=sqrt -> val acc=0.9060\n",
      "RF params: n_estimators=50, max_depth=None, max_features=log2 -> val acc=0.9090\n",
      "RF params: n_estimators=50, max_depth=5, max_features=sqrt -> val acc=0.8225\n",
      "RF params: n_estimators=50, max_depth=5, max_features=log2 -> val acc=0.8240\n",
      "RF params: n_estimators=50, max_depth=10, max_features=sqrt -> val acc=0.8955\n",
      "RF params: n_estimators=50, max_depth=10, max_features=log2 -> val acc=0.8980\n",
      "RF params: n_estimators=100, max_depth=None, max_features=sqrt -> val acc=0.9095\n",
      "RF params: n_estimators=100, max_depth=None, max_features=log2 -> val acc=0.9080\n",
      "RF params: n_estimators=100, max_depth=5, max_features=sqrt -> val acc=0.8255\n",
      "RF params: n_estimators=100, max_depth=5, max_features=log2 -> val acc=0.8215\n",
      "RF params: n_estimators=100, max_depth=10, max_features=sqrt -> val acc=0.8985\n",
      "RF params: n_estimators=100, max_depth=10, max_features=log2 -> val acc=0.9000\n",
      "RF params: n_estimators=200, max_depth=None, max_features=sqrt -> val acc=0.9080\n",
      "RF params: n_estimators=200, max_depth=None, max_features=log2 -> val acc=0.9100\n",
      "RF params: n_estimators=200, max_depth=5, max_features=sqrt -> val acc=0.8290\n",
      "RF params: n_estimators=200, max_depth=5, max_features=log2 -> val acc=0.8260\n",
      "RF params: n_estimators=200, max_depth=10, max_features=sqrt -> val acc=0.8975\n",
      "RF params: n_estimators=200, max_depth=10, max_features=log2 -> val acc=0.8985\n",
      "\n",
      "Best RF params (by validation): (200, None, 'log2')\n",
      "Best validation accuracy: 0.91\n",
      "RF 10-fold CV accuracies: [0.924 0.916 0.904 0.905 0.902 0.906 0.914 0.905 0.918 0.901]\n",
      "RF mean CV accuracy: 0.9094999999999999\n",
      "RF estimated generalization error (1-acc): 0.09050000000000014\n"
     ]
    }
   ],
   "source": [
    "# 2d:\n",
    "# === 2d: Random Forest – validation-based model selection ===\n",
    "\n",
    "rf_param_grid = {\n",
    "    \"n_estimators\": [50, 100, 200],\n",
    "    \"max_depth\": [None, 5, 10],\n",
    "    \"max_features\": [\"sqrt\", \"log2\"]\n",
    "}\n",
    "\n",
    "best_rf = None\n",
    "best_rf_params = None\n",
    "best_val_acc = -np.inf\n",
    "\n",
    "for n_trees in rf_param_grid[\"n_estimators\"]:\n",
    "    for depth in rf_param_grid[\"max_depth\"]:\n",
    "        for max_feat in rf_param_grid[\"max_features\"]:\n",
    "            rf = RandomForestClassifier(\n",
    "                n_estimators=n_trees,\n",
    "                max_depth=depth,\n",
    "                max_features=max_feat,\n",
    "                random_state=RANDOM_STATE\n",
    "            )\n",
    "            rf.fit(X_train, y_train)\n",
    "            y_val_pred = rf.predict(X_val)\n",
    "            acc = accuracy_score(y_val, y_val_pred)\n",
    "\n",
    "            print(f\"RF params: n_estimators={n_trees}, max_depth={depth}, \"\n",
    "                  f\"max_features={max_feat} -> val acc={acc:.4f}\")\n",
    "\n",
    "            if acc > best_val_acc:\n",
    "                best_val_acc = acc\n",
    "                best_rf = rf\n",
    "                best_rf_params = (n_trees, depth, max_feat)\n",
    "\n",
    "print(\"\\nBest RF params (by validation):\", best_rf_params)\n",
    "print(\"Best validation accuracy:\", best_val_acc)\n",
    "\n",
    "def manual_k_fold_cv(model_constructor, X, y, k=10, random_state=RANDOM_STATE):\n",
    "    \"\"\"\n",
    "    model_constructor: function with no args that returns a fresh model instance\n",
    "    k: number of folds\n",
    "    \"\"\"\n",
    "    np.random.seed(random_state)\n",
    "    N = X.shape[0]\n",
    "    indices = np.random.permutation(N)\n",
    "    fold_sizes = (N // k) * np.ones(k, dtype=int)\n",
    "    fold_sizes[:N % k] += 1  # אם N לא מתחלק ב-k\n",
    "\n",
    "    current = 0\n",
    "    accs = []\n",
    "\n",
    "    for fold_size in fold_sizes:\n",
    "        start, stop = current, current + fold_size\n",
    "        val_idx = indices[start:stop]\n",
    "        train_idx = np.concatenate([indices[:start], indices[stop:]])\n",
    "\n",
    "        X_tr, X_va = X[train_idx], X[val_idx]\n",
    "        y_tr, y_va = y[train_idx], y[val_idx]\n",
    "\n",
    "        model = model_constructor()\n",
    "        model.fit(X_tr, y_tr)\n",
    "        y_va_pred = model.predict(X_va)\n",
    "        fold_acc = accuracy_score(y_va, y_va_pred)\n",
    "        accs.append(fold_acc)\n",
    "\n",
    "        current = stop\n",
    "\n",
    "    return np.array(accs)\n",
    "\n",
    "# Usint the best parameters\n",
    "best_n_estimators, best_max_depth, best_max_features = best_rf_params\n",
    "\n",
    "def rf_constructor():\n",
    "    return RandomForestClassifier(\n",
    "        n_estimators=best_n_estimators,\n",
    "        max_depth=best_max_depth,\n",
    "        max_features=best_max_features,\n",
    "        random_state=RANDOM_STATE\n",
    "    )\n",
    "# calculating the model accuracy and generalization error\n",
    "rf_cv_accs = manual_k_fold_cv(rf_constructor, X_train, y_train, k=10)\n",
    "mean_CV_accuracy = rf_cv_accs.mean()\n",
    "genr_error = 1 - mean_CV_accuracy\n",
    "print(\"RF 10-fold CV accuracies:\", rf_cv_accs)\n",
    "print(\"RF mean CV accuracy:\", rf_cv_accs.mean())\n",
    "print(\"RF estimated generalization error (1-acc):\", 1 - rf_cv_accs.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027fd9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2e: Neural Network\n",
    "# – validation-based model selection ===\n",
    "\n",
    "hidden_layer_options = [\n",
    "    (5,),\n",
    "    (10,),\n",
    "    (20,),\n",
    "    (10, 10)  \n",
    "]\n",
    "\n",
    "best_mlp = None\n",
    "best_mlp_params = None\n",
    "best_mlp_val_acc = -np.inf\n",
    "\n",
    "for hidden in hidden_layer_options:\n",
    "    mlp = MLPClassifier(\n",
    "        hidden_layer_sizes=hidden,\n",
    "        activation='relu',\n",
    "        solver='adam',\n",
    "        max_iter=500,\n",
    "        random_state=RANDOM_STATE\n",
    "    )\n",
    "    mlp.fit(X_train, y_train)\n",
    "    y_val_pred = mlp.predict(X_val)\n",
    "    acc = accuracy_score(y_val, y_val_pred)\n",
    "    print(f\"MLP hidden={hidden} -> val acc={acc:.4f}\")\n",
    "\n",
    "    if acc > best_mlp_val_acc:\n",
    "        best_mlp_val_acc = acc\n",
    "        best_mlp = mlp\n",
    "        best_mlp_params = hidden\n",
    "\n",
    "print(\"\\nBest MLP hidden layer (by validation):\", best_mlp_params)\n",
    "print(\"Best MLP validation accuracy:\", best_mlp_val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68551492",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
